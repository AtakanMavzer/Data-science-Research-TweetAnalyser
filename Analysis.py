# -*- coding: utf-8 -*-
"""DataTweet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14rB76VSLW-SMSHlkPjPH_8zptxf_2W9R
"""

from textblob import TextBlob
import re
from sklearn import preprocessing
import pandas as pd
from   wordcloud import WordCloud
import matplotlib.pyplot as plt
import numpy as np

keywords=["Doge",
          "crypto",
          "dip",
          "bought",
          "buy",
          "TRX",
          "BTT",
          "TRON",
          "SUN"
          "pump",
          "Cryptography",
          "currency",
          "cryptocurrency",
          "blockchain",
          "block",
          "bitcoin",
          "coin",
          "eth",
          "etherium"
          "altcoin",
          "satoshi",
          "market",
          "Capitalization",
          "Distributed Ledger",
          "Mining",
          "Hashing",
          "Fork",
          "Soft Fork",
          "Hard Fork",
          "Address",
          "Private Key",
          "Public Key",
          "Exchange",
          "Wallet",
          "Paper Wallet",
          "Hardware Wallet",
          "Software Wallet",
          "Fungible",
          "HODL"]

#resMatch= get_Dominace_score(vitali["tweet"])
#print(resMatch,"\n", len(resMatch))

#vitali.fillna("str")

def get_Dominace_score(tweets):
  matched_list = []
  for tw in tweets:
    if (is_in(tw.lower())):
      matched_list.append(tw)
  return matched_list

def is_in (string):
  if any(keyword.lower() in string.lower() for keyword in keywords):
    return True
  else: return False

def cleaner (df): 

  def deleteK(text):
    if(text!=None):
      if text[-1]== 'K' or text[-1]== 'M' :
        text = text[:-1]
        text+='00'
        a=text.find('.')
        if a != -1:
          text = text[:a] + text[a+1:]
      return text
    else:
      a =text.find('.')
      if a != -1:
        text = text[:a] + text[a+1:]
      return text
    
  def cleanTxt(text):
    text = re.sub('@[A-Za-z0â€“9]+', '', text) #Removing @mentions
    text = re.sub('#', '', text) # Removing '#' hash tag
    text = re.sub('RT[\s]+', '', text) # Removing RT
    text = re.sub('https?:\/\/\S+', '', text) # Removing hyperlink
    return text
 
  df['tweet'] = df['tweet'].astype(str)
  df['retweet'] = df['retweet'].astype(str)
  df['likes'] = df['likes'].astype(str)
  df['comments'] = df['comments'].astype(str)
  df['date'] = pd.to_datetime(df['date'], format='%d/%m/%Y')
  df['tweet'] = df['tweet'].apply(cleanTxt)
  df['retweet'] = df['retweet'].apply(deleteK)
  df['likes'] = df['likes'].apply(deleteK)
  df['comments'] = df['comments'].apply(deleteK)
  

def getSubjectivity(text):
  return TextBlob(text).sentiment.subjectivity

# Create a function to get the polarity
def getPolarity(text):
  return  TextBlob(text).sentiment.polarity

# Create two new columns 'Subjectivity' & 'Polarity'
def get_Both(df):
  df['Subjectivity'] =df['tweet'].apply(getSubjectivity)
  df['Polarity'] = df['tweet'].apply(getPolarity)

# word cloud visualization
"""
def get_cloud():
allWords = ' '.join([twts for twts in df['Tweets']])
wordCloud = WordCloud(width=500, height=300, random_state=21, max_font_size=110).generate(allWords)
"""
def analyse_all(df):

  def getAnalysis(score):
    if score < 0:
      return 'Negative'
    elif score == 0:
      return 'Neutral'
    else:
      return 'Positive'

  df['Analysis'] = df['Polarity'].apply(getAnalysis)

def getMatch(df):
  df['match']=df["tweet"].apply(is_in)

def sumByDay(df):
  musk=df['score'].groupby(df['date'].dt.to_period('D')).sum()
  return musk

def get_score_emotion(df,isFLC,isInteractive,follower=55):

  max_f=55
  min_f=0.1
  normalizeF=(follower-min_f)/(max_f-min_f) 
  """
  if isFLC and isInteractive:





  elif isFLC and not isInteractive:




  elif not isFLC and not isInteractive:
  """
  def score(match,likes,comments,retweet):
    normalizeLikes= (int(likes))/(997900-64)
    normalizeComments = (float(comments))/(128300-200)
    normalizeRetweets = (int(retweet))/(254600-300)
    if match:
      return abs(normalizeLikes*normalizeComments*normalizeRetweets*normalizeF)
    else:
      return 0
    

  df['score'] =  df.apply(lambda df: score(df['match'], df['likes'],df['comments'],df['retweet']), axis=1)


def JustDoIt(df,isFLC,isInteractive):
  cleaner(df)
  getMatch(df)
  get_Both(df)
  get_score_emotion(df,isFLC,isInteractive)
  analyse_all(df)
  grouped=sumByDay(df)
  return grouped


def unsigned_cor(mergedStuffClose):
  ar=[mergedStuffClose[0]]
  for i in range(0,len(mergedStuffClose)-1):
    ar.append(abs(ar[i]-mergedStuffClose[i+1])+ar[i])
    print(ar[i])
  return ar
  
def dateF(text):
  temp= text[-2:]
  text = text[2:-2]
  constant = "20"
  temp = temp +  constant + text
  return temp

elon=pd.read_csv('Elon.csv') 
emin=pd.read_csv('Emin_Gun.csv') 
leonardo=pd.read_csv('Leo.csv') 
justinsun=pd.read_csv('justinsun.csv')
vitali=pd.read_csv('/content/vitali_2.csv') 
tom=pd.read_csv('/content/tom_Hanksu.csv') 

BTC_price=pd.read_csv('BTC_price.csv')
AVAX_price=pd.read_csv('avax_price.csv')
ETH_price = pd.read_csv('Etherium_price.csv')
Doge_price= pd.read_csv('BTC_price.csv')

def fillnaer(df):
  df['date'].fillna("01/01/2020", inplace=True)
  df['retweet'].fillna("0", inplace=True)
  df['likes'].fillna("0", inplace=True)
  df['comments'].fillna("0", inplace=True)


fillnaer(elon)
fillnaer(emin)
fillnaer(leonardo)
fillnaer(vitali)
fillnaer(justinsun)
fillnaer(tom)

AVAX_price.rename(columns={'snapped_at': 'date'}, inplace=True)

leonardo = leonardo.drop(0)
AVAX_price

musk = JustDoIt(tom,True,True)

d = []
for i,s in zip(musk,musk.index):
  d.append(
        {
            'date': s,
            'Number': i
        }
  )
  

person = pd.DataFrame(d)
"""
emin['retweet'] = pd.to_numeric(emin['retweet'])

emin.loc[emin['retweet'].idxmin()]
"""

Doge_price['date'] = pd.to_datetime(Doge_price['date'], format='%d/%m/%Y')
person['date'] = person['date'].dt.strftime('%Y-%m-%d')
person['date'] = pd.to_datetime(person['date'], format='%Y-%m-%d')


#elon = elon.sort_values(by="date")
Doge_price = Doge_price.sort_values(by="date")

#elonMusk

mergedStuff = pd.merge_asof(person, Doge_price, on=['date'])


mergedStuff = mergedStuff.sort_values(by="date")
mergedStuff

pc=np.gradient(mergedStuff['close'])

sc =np.gradient( mergedStuff['Number'])

pd.Series(sc).corr(pd.Series(pc).shift(0), method='kendall')

ab=mergedStuff['close']

#abc=unsigned_cor(mergedStuff['close'])

pd.Series(mergedStuff['Number'],).corr(pd.Series(ab).shift(0), method='kendall')

import matplotlib.pyplot as plt
plt.plot(ab)

plt.plot(abc)

plt.plot(sc)

pd.Series(mergedStuff['Number'],).corr(pd.Series(ab).shift(0), method='kendall')

